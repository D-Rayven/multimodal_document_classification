{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification d'images (MNIST) avec Keras (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/tpuser/.local/lib/python3.8/site-packages (2.10.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (1.23.3)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/tpuser/.local/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/tpuser/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/tpuser/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/tpuser/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/tpuser/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/tpuser/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/tpuser/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/tpuser/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/tpuser/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/tpuser/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la base MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première étape consiste à charger les données MNIST selon la documentation de keras https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration options\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Load the data\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement des données: l'entrée\n",
    "- normaliser les données (pour que l'entrée  soit dans [0,1])\n",
    "- remodeler les données d'entrée de sorte que les entrées `x` soient des vecteurs de taille 784, adaptés pour les RNN keras et non des images (matrices 28 x 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert into greyscale\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Reshape the data - MLPs do not understand such things as '2D'.\n",
    "# Reshape to 28 x 28 pixels = 784 features\n",
    "\n",
    "x_train_flat = x_train.reshape(-1, 784)\n",
    "x_train_flat.shape\n",
    "\n",
    "x_test_flat = x_test.reshape(-1, 784)\n",
    "x_test_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir les classes cibles en categories (et non numerique)\n",
    "- utiliser la fonction Keras `to_categorical()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les target classes to categorical ones\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Développer un MLP\n",
    "\n",
    "Commençons par les réseaux de neurones entièrement connectés (NN) également appelés perceptrons multicouches (MLP).\n",
    "Comme lors des TP précédents, le modèle séquentiel de keras sera utilisé avec des couches `Dense`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier essai\n",
    "Vous allez essayer de reproduire LeCun et al. 1998 dont les resultats sont disponibles sur le site Web du MNIST (http://yann.lecun.com/exdb/mnist/).\n",
    "le taux d'erreur signalé est de 4,7%.\n",
    "Nous commençons par créer l'architecture du MLP.\n",
    "   - dans ce cas le réseau de neurones est entièrement connecté: le NN est séquentiel,\n",
    "   - la première couche contient 300 neurones avec \"relu\" comme fonction d'activation,\n",
    "   - la couche de sortie contient 10 neurones (un par classe), la fonction d'activation est: `softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                3010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238,510\n",
      "Trainable params: 238,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "input_shape = (784,)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, activation='relu', input_shape=input_shape))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Créez un model Séquentiel (voir documentation Keras)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, activation=\"relu\", input_shape=(784,)))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, vous aller définir les parametres d'apprentissage du modèle \n",
    "- La première étape ici est de définir la fonction de coût (`loss`) et l'optimiseur (`optimizer`).\n",
    "    - Un choix naturel pour la fonction de perte `loss` est «catégorical_crossentropy» bien adaptée à la classification multiclasse. (La même vue dans le TP1)\n",
    "    - pour l'optimiseur, choisissez une descente de gradient stochastique simple (`SGD()`).\n",
    "    \n",
    "    \n",
    "\n",
    "- Lancer l'apprentissage et enregistrer le temps d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1283 - accuracy: 0.7498\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.8688\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4344 - accuracy: 0.8864\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3856 - accuracy: 0.8958\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3560 - accuracy: 0.9029\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.9076\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.9115\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3050 - accuracy: 0.9152\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2934 - accuracy: 0.9186\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2833 - accuracy: 0.9213\n",
      "Temps d'exécution:  12.786198139190674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1.1282881498336792,\n",
       "  0.5419073700904846,\n",
       "  0.4343818426132202,\n",
       "  0.38560807704925537,\n",
       "  0.3560313582420349,\n",
       "  0.3348805904388428,\n",
       "  0.318589985370636,\n",
       "  0.3050137758255005,\n",
       "  0.2933981120586395,\n",
       "  0.28330135345458984],\n",
       " 'accuracy': [0.7498499751091003,\n",
       "  0.8688499927520752,\n",
       "  0.8864499926567078,\n",
       "  0.8957833051681519,\n",
       "  0.9028833508491516,\n",
       "  0.9076166749000549,\n",
       "  0.9114500284194946,\n",
       "  0.9151999950408936,\n",
       "  0.9185500144958496,\n",
       "  0.9212833046913147]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilez le model et commencez l'apprentissage (avec 10 itérations)\n",
    "\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "optimizer = SGD()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_flat, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Temps d'exécution: \", end - start)\n",
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Mesurer le taux d'erreur sur la base `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2686576247215271\n",
      "Test accuracy: 0.9265000224113464\n",
      "Time :  0.39216113090515137\n"
     ]
    }
   ],
   "source": [
    "# Evaluez votre model après l'apprentissage sur la base donnée Test\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "score = model.evaluate(x_test_flat, y_test, verbose=0)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# Print Test Loss et Test Accuracy de votre modèle\n",
    "\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "print(\"Time : \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualisation des résultats d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisez les courbes (historique des données d'apprentissage et de test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Deuxième essai\n",
    "Essayons d'ameliorer un peu l'apprentissage en introduisant un peu de punch dans notre optimiseur.\n",
    "Pour ce faire, nous ajoutons un terme d'élan (`momentum = 0.9`) et une pénalité L2 (` decay = 1e-6`).\n",
    "\n",
    "Cela se fait en remplaçant l'instruction `\n",
    "optimiseur = SGD (), `\n",
    "par\n",
    "`\n",
    "optimizer = SGD (learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = False), `\n",
    "\n",
    "    \n",
    "  - Relancer l'apprentissage sur ce modele et enregistrer le temps d'apprentissage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                3010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238,510\n",
      "Trainable params: 238,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Mêmes étapes de création de modèle (nommez-le différemment), modifiez que l'optimiseur.\n",
    "\n",
    "modelBis = Sequential()\n",
    "\n",
    "modelBis.add(Dense(300, activation=\"relu\", input_shape=(784,)))\n",
    "modelBis.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "modelBis.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Mesurer le taux d'erreur sur la base `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.8683\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2523 - accuracy: 0.9292\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2006 - accuracy: 0.9441\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1685 - accuracy: 0.9517\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9592\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1282 - accuracy: 0.9651\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1143 - accuracy: 0.9682\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1037 - accuracy: 0.9717\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9736\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0864 - accuracy: 0.9767\n",
      "Temps d'exécution:  11.240235328674316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.4755588173866272,\n",
       "  0.2523110806941986,\n",
       "  0.20058713853359222,\n",
       "  0.1684914380311966,\n",
       "  0.14564384520053864,\n",
       "  0.12815560400485992,\n",
       "  0.11433720588684082,\n",
       "  0.10369344055652618,\n",
       "  0.09447868168354034,\n",
       "  0.08644025772809982],\n",
       " 'accuracy': [0.8682666420936584,\n",
       "  0.9291666746139526,\n",
       "  0.9441166520118713,\n",
       "  0.9517333507537842,\n",
       "  0.9592000246047974,\n",
       "  0.9651166796684265,\n",
       "  0.9682333469390869,\n",
       "  0.9717166423797607,\n",
       "  0.9735666513442993,\n",
       "  0.9767000079154968]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilez le model et commencez l'apprentissage (avec 10 itérations)\n",
    "\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "optimizer = SGD(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = False)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "modelBis.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = modelBis.fit(x_train_flat, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Temps d'exécution: \", end - start)\n",
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09588633477687836\n",
      "Test accuracy: 0.9718999862670898\n",
      "Time :  0.45223522186279297\n"
     ]
    }
   ],
   "source": [
    "# Evaluez votre model après l'apprentissage sur la base donnée Test\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "score = modelBis.evaluate(x_test_flat, y_test, verbose=0)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# Print Test Loss et Test Accuracy de votre modèle\n",
    "\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "print(\"Time : \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparer les temps d'apprentissage et les taux d'erreur. Que remarquez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier modèle (**model**):\n",
    "\n",
    "    - Test loss: 0.2686576247215271\n",
    "    - Test accuracy: 0.9265000224113464\n",
    "    - Time :  0.39216113090515137\n",
    "\n",
    "Second modèle (**modelBis**):\n",
    "\n",
    "    - Test loss: 0.09588633477687836\n",
    "    - Test accuracy: 0.9718999862670898\n",
    "    - Time :  0.45223522186279297\n",
    "\n",
    "On voit que nous avons moins environ deux fois moins d'erreurs sur notre second modèle et que la précision est meilleure avec le second également.\n",
    "En revanche, le temps d'exécution est un peu plus long pour le second modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisez les courbes (historique des données d'apprentissage et de test) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
